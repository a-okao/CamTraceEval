# カメラ＋マーカー手先軌道評価システム 要件定義書

この文書は、「コーディング用LLM」に渡して実装を依頼することを前提とした
**Python + OpenCV ベースの評価システム**の要件定義である。

---

## 0. 開発前提・制約

- 言語: Python 3.x
- 想定ライブラリ:
  - `opencv-python`（画像取得・処理）
  - `numpy`（数値計算）
  - `matplotlib`（可視化）
  - 標準ライブラリ（`csv`, `time`, `pathlib` など）
- 動作環境:
  - ノートPC (Windows / macOS / Linux のいずれか)
  - 内蔵 or 外付け Web カメラ 1 台

※ GUI は必須ではないが、最低限「ライブビュー表示ウィンドウ」と
「計測開始・終了トリガ」の操作方法（キー入力など）を用意してほしい。

---

## 1. システムの目的

- 手先（エンドエフェクタ）に取り付けたマーカーを Web カメラで撮像し、
  - 水平方向 100 mm の直線軌道
  - 直径 80 mm（半径 40 mm）の円軌道
    に対して、
  - 実際の手先軌道と**理想軌道との位置誤差**を定量化する。
  - 軌道を1往復 / 1周するのにかかった**時間・周期**を計測する。
- 学習制御「前後」のデータを比較できるような
  - CSV 出力
  - 軌跡プロット
  - 誤差グラフ
  を生成する。

---

## 2. 機能要件

### 2.1 モード構成

システムは、少なくとも以下の2つの評価モードを持つこと。

1. **直線軌道モード (LINE)**
   - 実空間上の始点・終点を結ぶ 100 mm の直線を理想軌道とする。
2. **円軌道モード (CIRCLE)**
   - 実空間上の中心座標と半径 40 mm の円を理想軌道とする。

モードの切り替えは、起動時の引数・設定ファイル・キーボード入力など
どの方法でもよいが、実装時に一貫した方法にすること。

---

### 2.2 カメラ画像取得

**必須要件**

- 指定したカメラデバイス（デフォルト 0 番）から連続フレームを取得する。
- 各フレームに対して以下を取得・記録する:
  - 画像 (`numpy.ndarray`)
  - 取得時刻（相対時刻 [s]）
- ライブビューウィンドウを表示し、マーカー位置（検出結果）を重ね描画して確認できること。

**インタフェース例（関数イメージ）**

~~~python
image, timestamp = get_frame()
~~~

---

### 2.3 マーカー検出

**前提**

- 手先には「背景と明確に色が異なる単色マーカー」が貼られている。
- マーカーは単一個（1点）である。

**要件**

- 各フレームからマーカーを検出し、画像座標 (u, v) [pixel] を返す。
- 色空間（例: BGR → HSV）変換＋しきい値処理＋輪郭抽出など、計算コストの低い方法でよい。
- マーカーが検出できなかった場合:
  - 座標は `None` または `NaN` として扱う。
  - ログに「検出失敗フレーム」であることを記録する。

**インタフェース例**

~~~python
u, v = detect_marker(image, config)
# config には HSV のしきい値などを含める
~~~

---

### 2.4 座標変換（ピクセル → 実座標 [mm]）

**目的**

- 画像上の座標 (u, v) [pixel] を、
  評価用の 2D 実座標 (x, y) [mm] に変換する。

**要件**

- キャリブレーション結果から変換行列を読み込み、
  - `(u, v) -> (x, y)` を計算する関数を実装する。
- 変換モデルは以下のいずれか（どちらかでよい）:
  1. 単純なスケーリング＋オフセット
     - 歪みが小さい前提
  2. 平面ホモグラフィ
     - 射影変換で補正

**キャリブレーション情報**

- 別途準備した JSON / YAML 等の設定ファイルに、
  - スケール係数、オフセット
  - または ホモグラフィ行列 3x3
  を保存しておき、起動時に読み込む想定でよい。

**インタフェース例**

~~~python
x, y = pixel_to_world(u, v, calib_params)
~~~

---

### 2.5 理想軌道の定義

#### 直線軌道 (LINE)

- 実座標系で
  - 始点 `P0 = (x0, y0)`
  - 終点 `P1 = (x1, y1)`
- 2点間距離が 100 mm になるように、キャリブレーション時に設定しておく。
- パラメトリック表現:

  \[
  P(s) = P_0 + s (P_1 - P_0), \quad s \in [0, 1]
  \]

#### 円軌道 (CIRCLE)

- 実座標系で
  - 中心 `C = (xc, yc)`
  - 半径 `R = 40 mm`
- パラメトリック表現:

  \[
  P(\theta) = C + (R \cos \theta, R \sin \theta)
  \]

---

### 2.6 誤差計算（位置誤差）

**入力**

- 各タイムステップ i の実座標: `(x_i, y_i)`
- 選択されたモード（LINE or CIRCLE）
- 理想軌道パラメータ（直線の2点 / 円の中心＋半径）

**出力**

- 各サンプルの誤差 `e_i` [mm]
- 誤差統計量:
  - RMSE（root mean square error）
  - 最大誤差

**定義**

1. 直線軌道の場合:
   - 実点 `(x_i, y_i)` から**直線への垂線距離**を誤差とする。
   - 計算上は、線分 P0–P1 の無限延長線上の距離でよい（必要なら線分に射影してもよい）。

2. 円軌道の場合:
   - 円の中心 C からの距離

     \[
     d_i = \sqrt{(x_i - x_c)^2 + (y_i - y_c)^2}
     \]

   - 誤差

     \[
     e_i = |d_i - R|
     \]

3. 統計量:
   - RMSE:

     \[
     \text{RMSE} = \sqrt{\frac{1}{N} \sum_{i} e_i^2}
     \]

   - 最大誤差:

     \[
     e_{\max} = \max_i e_i
     \]

---

### 2.7 時間評価

**目的**

- 直線往復・円周運動に対して、「1往復／1周」に要した時間を計測する。

**要件**

- 計測時間は、フレームのタイムスタンプから算出する。
- 計測開始・終了条件は以下のいずれかでよい:
  - キーボード操作（例: `s` で開始、`e` で終了）
  - もしくは、マーカーが特定領域を通過したときに自動判定（実装負荷高めなので任意）

**最低限の仕様**

- `t_start`: 計測開始時刻
- `t_end`: 計測終了時刻
- `T_meas = t_end - t_start` を「その試行の動作時間」として出力する。

（余裕があれば、直線往復の「行き時間」「帰り時間」や、円軌道の「1周周期」も自動抽出してよい）

---

### 2.8 データ保存・可視化

#### 2.8.1 CSV 出力

各試行ごとに CSV ファイルを保存する。

**列の例**

- `time` : 相対時刻 [s]
- `u`, `v` : ピクセル座標（検出できなかった場合は空欄 or NaN）
- `x`, `y` : 実座標 [mm]
- `error` : 理想軌道との距離 [mm]

ファイル名の例:

- `mode_line_before.csv`
- `mode_line_after.csv`
- `mode_circle_before.csv`
- `mode_circle_after.csv`

のように、モードと「学習前後」がわかる命名にしておくと便利。

#### 2.8.2 プロット出力

各試行ごとに、以下の図を画像ファイル (PNG or PDF) として保存する。

1. **軌跡図**
   - 理想軌道（直線 or 円）を線で描画。
   - 実軌道（x, y の時系列）を折れ線または点で描画。
   - 軸は [mm] 単位。
2. **誤差の時間変化**
   - 横軸: 時間 [s]
   - 縦軸: 誤差 e [mm]

可能なら、「学習前」と「学習後」を同じ図に重ねて表示できるオプションがあると望ましい。

---

## 3. 非機能要件

- フレームレート:
  - 15 fps 以上（推奨 30 fps）
- リアルタイム性:
  - 可能な限り、マーカー検出結果をライブビュー上に描画する。
- 再利用性:
  - キャリブレーションパラメータや色しきい値などを
    外部設定ファイル（JSON/YAML）から読み書きできるようにする。
- エラーハンドリング:
  - カメラが開けない場合・マーカー未検出が続く場合などに、
    標準出力に警告メッセージを出す。

---

## 4. モジュール構成（例）

実装用の参考として、Python モジュール・関数の構成案を示す。

~~~text
project_root/
  main.py               # エントリポイント
  config.yaml           # キャリブレーション・色しきい値など
  camera.py             # カメラ関連処理
  marker.py             # マーカー検出
  calib.py              # ピクセル→実座標変換
  trajectory.py         # 理想軌道の定義・最近傍距離の計算
  evaluator.py          # 誤差計算・統計量算出
  io_utils.py           # CSV 保存・画像保存
~~~

### 各モジュールの責務イメージ

- `camera.py`
  - カメラ初期化、フレーム取得、ウィンドウ表示
- `marker.py`
  - 画像からマーカーの (u, v) を検出
- `calib.py`
  - 設定ファイルからキャリブパラメータ読み込み
  - `pixel_to_world(u, v) -> (x, y)`
- `trajectory.py`
  - LINE/CIRCLE の理想軌道をパラメータで保持
  - 与えられた点 (x, y) に対する最近傍距離を計算
- `evaluator.py`
  - 誤差列 `e_i` の生成
  - RMSE, max error, 動作時間などの計算
- `io_utils.py`
  - CSV 書き出し
  - Matplotlib でのプロット作成・保存

---

## 5. 想定する実行フロー（高レベル）

1. 設定ファイル読み込み（キャリブ・色しきい値・モードなど）
2. カメラ初期化
3. ライブビュー開始
4. ユーザがキー入力等で「計測開始」
5. 計測中:
   - フレーム取得
   - マーカー検出 → (u, v)
   - 座標変換 → (x, y)
   - 誤差 `e_i` 計算
   - すべてのデータをバッファに保存
6. ユーザが「計測終了」
7. 誤差統計量・動作時間を計算
8. CSV 保存・プロット保存
9. （必要なら）コンソールに統計値を表示

---

## 6. テスト観点

- 既知の位置（例えばキャリブレーション対象点）にマーカーを置き、
  実座標と計算結果がどれくらい一致するかを確認できると望ましい。
- マーカーがフレーム外に一時的に出た場合でも、
  プログラムがクラッシュせずに動作を継続できること。
